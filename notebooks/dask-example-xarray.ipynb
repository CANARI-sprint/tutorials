{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1fad20f-56cd-4d9c-a61a-687ff6c97978",
   "metadata": {},
   "source": [
    "# Xarray with Dask Gateway\n",
    "This is based on the JASMIN examples from https://github.com/cedadev/jasmin-daskgateway/blob/main/examples/ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747b56ed-5dff-4d33-9481-2f87ad23b4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import dask_gateway\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display\n",
    "import xarray as xr\n",
    "import glob\n",
    "# Who doesn't want a loading bar?\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bb620c-c27f-4f6a-936b-b4c18e53bd01",
   "metadata": {},
   "source": [
    "If you don't want to use the dask gateway, skip to the cell with the starting comment of \"Set up file paths so we can select multiple years and multiple ensemble memebers. Using temperature as an example.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72d973a-b7a5-4c74-ae5d-4ed1fb313349",
   "metadata": {},
   "outputs": [],
   "source": [
    "gw = dask_gateway.Gateway(\"https://dask-gateway.jasmin.ac.uk\", auth=\"jupyterhub\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2d8b1c-f238-46e5-a0ac-0d51fd092cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = gw.cluster_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298d3fb3-7878-4325-a93f-0d57114d26d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fd7398-7b00-4834-bbf2-273b0592adce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up your cluster options - you'll have to tailor this to your own use case.\n",
    "options.worker_cores = 4\n",
    "options.worker_threads = 8\n",
    "# Specify which conda env to use, this must match the versions of python and dask (and a few other libraries) used on the notebook service\n",
    "options.worker_setup='source /apps/jasmin/jaspy/mambaforge_envs/jaspy3.10/mf-22.11.1-4/bin/activate /gws/smf/j04/canari/dask-env'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237f4920-20cb-4f66-a9a5-4df39f5ed792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dask cluster, or, if one already exists, connect to it.\n",
    "# This stage creates the scheduler job in SLURM, so may take some time while your job queues.\n",
    "clusters = gw.list_clusters()\n",
    "if not clusters:\n",
    "    cluster = gw.new_cluster(options, shutdown_on_close=False)\n",
    "else:\n",
    "    cluster = gw.connect(clusters[0].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d731f0db-ab8a-40ff-8816-d03acbaaed06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create at least one worker, and allow your cluster to scale to 15.\n",
    "# The max JASMIN allows is 16, but one of these is used as the scheduler.\n",
    "cluster.adapt(minimum=1, maximum=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aca2996-3a94-49fa-a409-995146a73133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a dask client.\n",
    "client = cluster.get_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebecaf24-7bb1-4243-b8d0-8a1173e258bf",
   "metadata": {},
   "source": [
    "The link to the dashboard will become visible below. We recommend having it open on one side of your screen while using your notebook on the other side. This can take some effort to arrange your windows, but seeing them both at the same is very useful when learning.\n",
    "\n",
    "On JASMIN the Dashboard can be shown by connecting a web browser to the address (something like https://dask-gateway.jasmin.ac.uk/clusters/3189803deca44f60bdc9653e06cc180d/status) returned by the cell below. But this is only available on the JASMIN network, so we have to do it over the [Jasmin No Machine login](https://help.jasmin.ac.uk/docs/interactive-computing/graphical-linux-desktop-access-using-nx/).\n"
    "For documentation about the Dashboard, please see https://docs.dask.org/en/stable/dashboard.html.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4c6f8f-f02d-4fdc-b48e-be7138fada01",
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6af3c70-3faf-4340-bf61-1279bef497b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick how many ensemble members you wish to look at\n",
    "ensemble_members = range(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc03afe-adc5-45ef-8d0b-3873334bfd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick how many years you wish to look at\n",
    "years = range(1950, 1953)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac072e38-d2fa-4b8f-a47f-91cac068b27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up file paths so we can select multiple years and multiple ensemble memebers. Using temperature as an example. \n",
    "datadir = '/gws/nopw/j04/canari/shared/large-ensemble/priority/HIST2/'\n",
    "filepath_middle = '/OCN/yearly/'\n",
    "filepath_end = '/*_votemper.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbca9e7-7e37-40be-9f9a-f3660b9a5ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we were only looking at one ensemble member, we'd be able to simply use xr.open_mfdataset. \n",
    "# However, the files from multiple ensembles can't be imediately combined into one dataset, becasue there isn't a coordinate to combine over. \n",
    "# Therefore, loop over the ensemble members and open all the data from each. \n",
    "# We can then add a dimension/coordinate to each dataset called 'ensemble_member' which we'll use to keep track of which ensemble member it is. \n",
    "# We then added each dataset (one per ensemble member) to a list of datasets.\n",
    "# If dask is installed, xarray loads data 'lazily' - all computation is deferred until explicitly requested. This provides the ability to do out of RAM computation.\n",
    "datasets = []\n",
    "# Outermost loop is through ensemble members\n",
    "for index, member in enumerate(tqdm(ensemble_members)):\n",
    "    paths = []\n",
    "    # Inner loop is through years - mf_opendataset will concatentate the datasets from different years together automatically if it is passed them as a list.\n",
    "    for year in years:\n",
    "        paths.append(glob.glob((datadir + str(member) + filepath_middle + str(year) + filepath_end))[0])\n",
    "    print(paths)\n",
    "    temp_dataset = xr.open_mfdataset(paths)\n",
    "    temp_dataset['ensemble_member'] = ensemble_members[index]\n",
    "    temp_dataset = temp_dataset.expand_dims(dim='ensemble_member').set_coords('ensemble_member')\n",
    "    datasets.append(temp_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cedbcb8-2cda-4532-9b79-9eee6c4cfb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check our list of datasets look like we expect\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31c1b6b-33c9-40e5-af15-a4d23131b07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we can concatentate these datasets over our 'ensemble_member' dimension. \n",
    "dataset= xr.concat(datasets,'ensemble_member')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8575bc87-f7dd-445d-8144-0cb2d90f6937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This leaves us with one dataset. Let's have a look at it. (This is still lazy, as can be seen by the data variables being dask arrays, rather than numpy arrays.)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbb8e31-87c6-4220-91ed-da29dfeed47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we look at the dataarray, rather than the dataset, we can see the chunksizses. Ideally, these would be around 100MB, so ours are smaller than ideal. \n",
    "# This is due to there being one chunk per month, I believe. \n",
    "dataset.votemper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3582e2da-abf4-4d73-b3d5-ce5aae859010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could rechunk our data. It might be worth thinking about the chunks in the dataset itself, if you are using a file format that supports chunking.\n",
    "rechunked_dataset = dataset.chunk(chunks={\"time_counter\": 12, \"deptht\": 75, \"y\": 302, \"x\": 361})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310f8715-52f7-4988-9600-e815643c7ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rechunked_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c663c505-76b6-41a7-af5c-663ce32d0627",
   "metadata": {},
   "outputs": [],
   "source": [
    "rechunked_dataset.votemper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e861eb5-cf90-4cd7-a3a0-d3f3d3c322bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could take the mean of all the same months across all the years (i.e. all the Jans, etc) - these groupby style of operations are really typical of xarray.\n",
    "# I'm not going to use the rechunked dataset here because I am averaging over each month across the years. \n",
    "means = dataset.groupby(dataset.time_counter.dt.month).mean(dim=[\"time_counter\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7da288e-ce6c-4682-ad8a-aae9b98bb6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb05abd5-c63d-4213-8411-e82642bb7175",
   "metadata": {},
   "outputs": [],
   "source": [
    "means.votemper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b64aa7-f08f-4491-abbd-fd22bc7eb1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting actually causes the relevant bits of the mean calculation to be performed. (To do the whole calculation you could call .compute(), but I wouldn't usually explicitly do this.)\n",
    "means.votemper[0, 0, 0, :, :].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8a0fc1-7c9c-49f3-bbdd-709104c43ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# But if I look at the dataset again, the data variables are still dask arrays - the data that is realised when plotting doesn't stay in memory (there are ways to explicitly request it). \n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40da4fb2-d329-46c1-b7c4-609e37fa31d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make another plot\n",
    "# For my quick demo purposes, let us pick a single point in the North Atlantic\n",
    "y_selected = 800\n",
    "x_selected = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ab7051-cd29-4705-b94a-1c704d63162e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the lat and lon of that point\n",
    "lon = dataset.nav_lon.values[y_selected, x_selected]\n",
    "lat = dataset.nav_lat.values[y_selected, x_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f50015-c267-482b-b975-a61defcfc5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the dataset so that we end up with all the ensembles, times and depths for that single point\n",
    "selected_data = dataset.sel({\"y\": y_selected, \"x\": x_selected})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3c2840-ae0d-4f4b-b8a1-cbaf5aeef479",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824e998c-12ee-4060-91e3-9a9fb50d6541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And let's plot them\n",
    "selected_data.votemper[0, 0, :].plot.line(y=\"deptht\")\n",
    "selected_data.votemper[0, 6, :].plot.line(y=\"deptht\")\n",
    "plt.title(f\"lat: {lat}, lon: {lon}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be2a5a6-a450-4ef9-9835-2fb18e22ff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I probably don't actually want to find the median temp across the whole world at each ensemble/time/depth, but maybe this shows the dask gateway being used better, so we can run it if we want to. \n",
    "# medians = dataset.median(dim=[\"x\", \"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534d6180-f3d8-4d17-9f2e-8eec3264abb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e14786-f06c-4fcd-b353-3ef49f4b6174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As I've said previously, I wouldn't really run .compute() usually, but let's try it as a demo. \n",
    "# medians.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8197381e-2f7a-4aae-ad2a-96ec542d28aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.shutdown() #shutdown our dask cluster. If we want to use it for something else we could remove this, but starting a new one only takes a few seconds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CANARI-dask",
   "language": "python",
   "name": "canari-dask"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
